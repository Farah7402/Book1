{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Book_1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmhJq/jo5s3sSkGE+HEjHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farah7402/Book1/blob/main/Book_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyItiIZrYO5g",
        "outputId": "a7d96f7d-54f6-468b-fdd4-07f2b66fd9f4"
      },
      "source": [
        "!git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n",
            "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
            "           [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]\n",
            "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
            "           <command> [<args>]\n",
            "\n",
            "These are common Git commands used in various situations:\n",
            "\n",
            "start a working area (see also: git help tutorial)\n",
            "   clone      Clone a repository into a new directory\n",
            "   init       Create an empty Git repository or reinitialize an existing one\n",
            "\n",
            "work on the current change (see also: git help everyday)\n",
            "   add        Add file contents to the index\n",
            "   mv         Move or rename a file, a directory, or a symlink\n",
            "   reset      Reset current HEAD to the specified state\n",
            "   rm         Remove files from the working tree and from the index\n",
            "\n",
            "examine the history and state (see also: git help revisions)\n",
            "   bisect     Use binary search to find the commit that introduced a bug\n",
            "   grep       Print lines matching a pattern\n",
            "   log        Show commit logs\n",
            "   show       Show various types of objects\n",
            "   status     Show the working tree status\n",
            "\n",
            "grow, mark and tweak your common history\n",
            "   branch     List, create, or delete branches\n",
            "   checkout   Switch branches or restore working tree files\n",
            "   commit     Record changes to the repository\n",
            "   diff       Show changes between commits, commit and working tree, etc\n",
            "   merge      Join two or more development histories together\n",
            "   rebase     Reapply commits on top of another base tip\n",
            "   tag        Create, list, delete or verify a tag object signed with GPG\n",
            "\n",
            "collaborate (see also: git help workflows)\n",
            "   fetch      Download objects and refs from another repository\n",
            "   pull       Fetch from and integrate with another repository or a local branch\n",
            "   push       Update remote refs along with associated objects\n",
            "\n",
            "'git help -a' and 'git help -g' list available subcommands and some\n",
            "concept guides. See 'git help <command>' or 'git help <concept>'\n",
            "to read about a specific subcommand or concept.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2LrPz4cYcwx",
        "outputId": "ea75d4e3-1e2e-4f0f-fc0b-46baab22c96f"
      },
      "source": [
        "!git init"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyTdujsfYj22",
        "outputId": "a5d6d712-4843-42a9-dc81-a2edda747752"
      },
      "source": [
        "! git clone https://github.com/Farah7402/Book1.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Book1'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvODmdONehAz"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from keras import utils as np_utils \n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbO_2UYpBeKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffaa92f-c930-4ab6-f5c4-d704624b3d7e"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train,y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "print('x_train =', x_train.shape)\n",
        "print('x_valid =', x_valid.shape)\n",
        "print('x_test =', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train = (45000, 32, 32, 3)\n",
            "x_valid = (5000, 32, 32, 3)\n",
            "x_test = (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84fRR_HpWKEW"
      },
      "source": [
        "#normalize\n",
        "\n",
        "mean = np.mean(x_train, axis=(0,1,2,3))\n",
        "std = np.std(x_train, axis = (0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_valid = (x_valid-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTInqjPBgkN"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n",
        "y_test =  tf.keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl_L2ZLDTmnd"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1,horizontal_flip=True,vertical_flip=True)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kkY7DONCqAB",
        "outputId": "a8ab8c1b-f6c2-44a4-ba48-f5a614153e33"
      },
      "source": [
        "base_hidden_units =32\n",
        "weight_decay=1e-4\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(base_hidden_units * 2, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(base_hidden_units*4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(base_hidden_units*4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 32)        18464     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         36992     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 253,834\n",
            "Trainable params: 253,002\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4fj4bG1Z02h"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center = False,\n",
        "    samplewise_center =False,\n",
        "    featurewise_std_normalization = False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dqiBcVRKhQJ",
        "outputId": "d2a0a3dd-7b00-4cc6-8339-87b7f9e0eecf"
      },
      "source": [
        "batch_size = 64\n",
        "epochs =125\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.125epochs.hdf5', verbose=1,save_best_only=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr = 0.0005, decay = 1e-6)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer], steps_per_epoch = x_train.shape[0] // batch_size, epochs=epochs, verbose=2, validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "703/703 - 54s - loss: 0.7483 - accuracy: 0.7557 - val_loss: 0.5796 - val_accuracy: 0.8174\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.57960, saving model to model.125epochs.hdf5\n",
            "Epoch 2/125\n",
            "703/703 - 31s - loss: 0.7119 - accuracy: 0.7660 - val_loss: 0.6688 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.57960\n",
            "Epoch 3/125\n",
            "703/703 - 31s - loss: 0.6915 - accuracy: 0.7747 - val_loss: 0.7590 - val_accuracy: 0.7738\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.57960\n",
            "Epoch 4/125\n",
            "703/703 - 31s - loss: 0.6731 - accuracy: 0.7826 - val_loss: 0.5837 - val_accuracy: 0.8208\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.57960\n",
            "Epoch 5/125\n",
            "703/703 - 31s - loss: 0.6758 - accuracy: 0.7817 - val_loss: 0.6234 - val_accuracy: 0.8098\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.57960\n",
            "Epoch 6/125\n",
            "703/703 - 31s - loss: 0.6547 - accuracy: 0.7897 - val_loss: 0.5361 - val_accuracy: 0.8352\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.57960 to 0.53612, saving model to model.125epochs.hdf5\n",
            "Epoch 7/125\n",
            "703/703 - 31s - loss: 0.6462 - accuracy: 0.7926 - val_loss: 0.5933 - val_accuracy: 0.8186\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.53612\n",
            "Epoch 8/125\n",
            "703/703 - 31s - loss: 0.6317 - accuracy: 0.8014 - val_loss: 0.5507 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.53612\n",
            "Epoch 9/125\n",
            "703/703 - 31s - loss: 0.6328 - accuracy: 0.7986 - val_loss: 0.5613 - val_accuracy: 0.8326\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.53612\n",
            "Epoch 10/125\n",
            "703/703 - 31s - loss: 0.6303 - accuracy: 0.8005 - val_loss: 0.5518 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.53612\n",
            "Epoch 11/125\n",
            "703/703 - 31s - loss: 0.6191 - accuracy: 0.8059 - val_loss: 0.5557 - val_accuracy: 0.8336\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.53612\n",
            "Epoch 12/125\n",
            "703/703 - 31s - loss: 0.6082 - accuracy: 0.8105 - val_loss: 0.5422 - val_accuracy: 0.8396\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.53612\n",
            "Epoch 13/125\n",
            "703/703 - 31s - loss: 0.6103 - accuracy: 0.8106 - val_loss: 0.5562 - val_accuracy: 0.8324\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.53612\n",
            "Epoch 14/125\n",
            "703/703 - 31s - loss: 0.6044 - accuracy: 0.8110 - val_loss: 0.5226 - val_accuracy: 0.8490\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.53612 to 0.52256, saving model to model.125epochs.hdf5\n",
            "Epoch 15/125\n",
            "703/703 - 31s - loss: 0.6012 - accuracy: 0.8131 - val_loss: 0.4999 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.52256 to 0.49993, saving model to model.125epochs.hdf5\n",
            "Epoch 16/125\n",
            "703/703 - 31s - loss: 0.5942 - accuracy: 0.8195 - val_loss: 0.5694 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.49993\n",
            "Epoch 17/125\n",
            "703/703 - 31s - loss: 0.5905 - accuracy: 0.8183 - val_loss: 0.5669 - val_accuracy: 0.8360\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.49993\n",
            "Epoch 18/125\n",
            "703/703 - 31s - loss: 0.5902 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.49993\n",
            "Epoch 19/125\n",
            "703/703 - 31s - loss: 0.5879 - accuracy: 0.8198 - val_loss: 0.5213 - val_accuracy: 0.8506\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.49993\n",
            "Epoch 20/125\n",
            "703/703 - 31s - loss: 0.5816 - accuracy: 0.8253 - val_loss: 0.5386 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.49993\n",
            "Epoch 21/125\n",
            "703/703 - 31s - loss: 0.5827 - accuracy: 0.8237 - val_loss: 0.5380 - val_accuracy: 0.8492\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.49993\n",
            "Epoch 22/125\n",
            "703/703 - 31s - loss: 0.5758 - accuracy: 0.8267 - val_loss: 0.4925 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.49993 to 0.49248, saving model to model.125epochs.hdf5\n",
            "Epoch 23/125\n",
            "703/703 - 31s - loss: 0.5733 - accuracy: 0.8285 - val_loss: 0.5463 - val_accuracy: 0.8504\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.49248\n",
            "Epoch 24/125\n",
            "703/703 - 31s - loss: 0.5698 - accuracy: 0.8280 - val_loss: 0.5062 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.49248\n",
            "Epoch 25/125\n",
            "703/703 - 31s - loss: 0.5696 - accuracy: 0.8286 - val_loss: 0.4999 - val_accuracy: 0.8602\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.49248\n",
            "Epoch 26/125\n",
            "703/703 - 31s - loss: 0.5656 - accuracy: 0.8296 - val_loss: 0.5833 - val_accuracy: 0.8372\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.49248\n",
            "Epoch 27/125\n",
            "703/703 - 31s - loss: 0.5633 - accuracy: 0.8320 - val_loss: 0.5134 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.49248\n",
            "Epoch 28/125\n",
            "703/703 - 31s - loss: 0.5632 - accuracy: 0.8343 - val_loss: 0.5056 - val_accuracy: 0.8534\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.49248\n",
            "Epoch 29/125\n",
            "703/703 - 31s - loss: 0.5615 - accuracy: 0.8329 - val_loss: 0.5241 - val_accuracy: 0.8538\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.49248\n",
            "Epoch 30/125\n",
            "703/703 - 31s - loss: 0.5621 - accuracy: 0.8332 - val_loss: 0.5191 - val_accuracy: 0.8516\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.49248\n",
            "Epoch 31/125\n",
            "703/703 - 31s - loss: 0.5540 - accuracy: 0.8391 - val_loss: 0.5060 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.49248\n",
            "Epoch 32/125\n",
            "703/703 - 31s - loss: 0.5458 - accuracy: 0.8392 - val_loss: 0.4930 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.49248\n",
            "Epoch 33/125\n",
            "703/703 - 31s - loss: 0.5496 - accuracy: 0.8371 - val_loss: 0.5214 - val_accuracy: 0.8572\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.49248\n",
            "Epoch 34/125\n",
            "703/703 - 31s - loss: 0.5507 - accuracy: 0.8375 - val_loss: 0.5254 - val_accuracy: 0.8542\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.49248\n",
            "Epoch 35/125\n",
            "703/703 - 31s - loss: 0.5462 - accuracy: 0.8408 - val_loss: 0.5128 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.49248\n",
            "Epoch 36/125\n",
            "703/703 - 31s - loss: 0.5467 - accuracy: 0.8379 - val_loss: 0.5198 - val_accuracy: 0.8572\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.49248\n",
            "Epoch 37/125\n",
            "703/703 - 31s - loss: 0.5442 - accuracy: 0.8415 - val_loss: 0.4951 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.49248\n",
            "Epoch 38/125\n",
            "703/703 - 31s - loss: 0.5400 - accuracy: 0.8419 - val_loss: 0.5208 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.49248\n",
            "Epoch 39/125\n",
            "703/703 - 31s - loss: 0.5451 - accuracy: 0.8431 - val_loss: 0.5253 - val_accuracy: 0.8544\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.49248\n",
            "Epoch 40/125\n",
            "703/703 - 31s - loss: 0.5368 - accuracy: 0.8445 - val_loss: 0.5196 - val_accuracy: 0.8604\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.49248\n",
            "Epoch 41/125\n",
            "703/703 - 31s - loss: 0.5370 - accuracy: 0.8443 - val_loss: 0.5046 - val_accuracy: 0.8592\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.49248\n",
            "Epoch 42/125\n",
            "703/703 - 31s - loss: 0.5327 - accuracy: 0.8445 - val_loss: 0.5240 - val_accuracy: 0.8576\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.49248\n",
            "Epoch 43/125\n",
            "703/703 - 31s - loss: 0.5306 - accuracy: 0.8463 - val_loss: 0.4839 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.49248 to 0.48387, saving model to model.125epochs.hdf5\n",
            "Epoch 44/125\n",
            "703/703 - 31s - loss: 0.5332 - accuracy: 0.8462 - val_loss: 0.4557 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.48387 to 0.45569, saving model to model.125epochs.hdf5\n",
            "Epoch 45/125\n",
            "703/703 - 31s - loss: 0.5282 - accuracy: 0.8474 - val_loss: 0.5358 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.45569\n",
            "Epoch 46/125\n",
            "703/703 - 31s - loss: 0.5334 - accuracy: 0.8476 - val_loss: 0.5279 - val_accuracy: 0.8526\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.45569\n",
            "Epoch 47/125\n",
            "703/703 - 31s - loss: 0.5291 - accuracy: 0.8486 - val_loss: 0.4711 - val_accuracy: 0.8682\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.45569\n",
            "Epoch 48/125\n",
            "703/703 - 31s - loss: 0.5264 - accuracy: 0.8477 - val_loss: 0.4842 - val_accuracy: 0.8680\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.45569\n",
            "Epoch 49/125\n",
            "703/703 - 31s - loss: 0.5212 - accuracy: 0.8515 - val_loss: 0.5086 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.45569\n",
            "Epoch 50/125\n",
            "703/703 - 31s - loss: 0.5235 - accuracy: 0.8505 - val_loss: 0.4596 - val_accuracy: 0.8764\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.45569\n",
            "Epoch 51/125\n",
            "703/703 - 31s - loss: 0.5225 - accuracy: 0.8505 - val_loss: 0.4729 - val_accuracy: 0.8758\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.45569\n",
            "Epoch 52/125\n",
            "703/703 - 31s - loss: 0.5217 - accuracy: 0.8512 - val_loss: 0.4893 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.45569\n",
            "Epoch 53/125\n",
            "703/703 - 31s - loss: 0.5202 - accuracy: 0.8529 - val_loss: 0.5000 - val_accuracy: 0.8680\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.45569\n",
            "Epoch 54/125\n",
            "703/703 - 31s - loss: 0.5227 - accuracy: 0.8512 - val_loss: 0.5100 - val_accuracy: 0.8612\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.45569\n",
            "Epoch 55/125\n",
            "703/703 - 31s - loss: 0.5178 - accuracy: 0.8532 - val_loss: 0.5295 - val_accuracy: 0.8580\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.45569\n",
            "Epoch 56/125\n",
            "703/703 - 31s - loss: 0.5146 - accuracy: 0.8552 - val_loss: 0.4905 - val_accuracy: 0.8678\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.45569\n",
            "Epoch 57/125\n",
            "703/703 - 31s - loss: 0.5140 - accuracy: 0.8558 - val_loss: 0.4936 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.45569\n",
            "Epoch 58/125\n",
            "703/703 - 31s - loss: 0.5185 - accuracy: 0.8528 - val_loss: 0.4477 - val_accuracy: 0.8860\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.45569 to 0.44768, saving model to model.125epochs.hdf5\n",
            "Epoch 59/125\n",
            "703/703 - 31s - loss: 0.5124 - accuracy: 0.8551 - val_loss: 0.4616 - val_accuracy: 0.8776\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.44768\n",
            "Epoch 60/125\n",
            "703/703 - 31s - loss: 0.5236 - accuracy: 0.8517 - val_loss: 0.4718 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.44768\n",
            "Epoch 61/125\n",
            "703/703 - 31s - loss: 0.5109 - accuracy: 0.8574 - val_loss: 0.5107 - val_accuracy: 0.8642\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.44768\n",
            "Epoch 62/125\n",
            "703/703 - 31s - loss: 0.5098 - accuracy: 0.8539 - val_loss: 0.4575 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.44768\n",
            "Epoch 63/125\n",
            "703/703 - 31s - loss: 0.5022 - accuracy: 0.8588 - val_loss: 0.4455 - val_accuracy: 0.8872\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.44768 to 0.44555, saving model to model.125epochs.hdf5\n",
            "Epoch 64/125\n",
            "703/703 - 31s - loss: 0.5110 - accuracy: 0.8553 - val_loss: 0.4820 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.44555\n",
            "Epoch 65/125\n",
            "703/703 - 31s - loss: 0.5086 - accuracy: 0.8570 - val_loss: 0.4676 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.44555\n",
            "Epoch 66/125\n",
            "703/703 - 31s - loss: 0.5067 - accuracy: 0.8574 - val_loss: 0.5335 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.44555\n",
            "Epoch 67/125\n",
            "703/703 - 31s - loss: 0.5069 - accuracy: 0.8572 - val_loss: 0.5525 - val_accuracy: 0.8550\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.44555\n",
            "Epoch 68/125\n",
            "703/703 - 31s - loss: 0.5135 - accuracy: 0.8551 - val_loss: 0.4691 - val_accuracy: 0.8724\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.44555\n",
            "Epoch 69/125\n",
            "703/703 - 31s - loss: 0.5134 - accuracy: 0.8569 - val_loss: 0.5038 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.44555\n",
            "Epoch 70/125\n",
            "703/703 - 31s - loss: 0.5039 - accuracy: 0.8582 - val_loss: 0.4688 - val_accuracy: 0.8762\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.44555\n",
            "Epoch 71/125\n",
            "703/703 - 31s - loss: 0.5099 - accuracy: 0.8565 - val_loss: 0.4765 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.44555\n",
            "Epoch 72/125\n",
            "703/703 - 31s - loss: 0.5052 - accuracy: 0.8595 - val_loss: 0.5749 - val_accuracy: 0.8520\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.44555\n",
            "Epoch 73/125\n",
            "703/703 - 31s - loss: 0.4999 - accuracy: 0.8606 - val_loss: 0.4746 - val_accuracy: 0.8774\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.44555\n",
            "Epoch 74/125\n",
            "703/703 - 31s - loss: 0.5034 - accuracy: 0.8596 - val_loss: 0.5040 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.44555\n",
            "Epoch 75/125\n",
            "703/703 - 31s - loss: 0.5056 - accuracy: 0.8568 - val_loss: 0.4850 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.44555\n",
            "Epoch 76/125\n",
            "703/703 - 31s - loss: 0.4995 - accuracy: 0.8610 - val_loss: 0.4691 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.44555\n",
            "Epoch 77/125\n",
            "703/703 - 31s - loss: 0.5049 - accuracy: 0.8599 - val_loss: 0.5470 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.44555\n",
            "Epoch 78/125\n",
            "703/703 - 31s - loss: 0.5008 - accuracy: 0.8591 - val_loss: 0.4760 - val_accuracy: 0.8772\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.44555\n",
            "Epoch 79/125\n",
            "703/703 - 31s - loss: 0.4972 - accuracy: 0.8617 - val_loss: 0.4384 - val_accuracy: 0.8858\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.44555 to 0.43838, saving model to model.125epochs.hdf5\n",
            "Epoch 80/125\n",
            "703/703 - 31s - loss: 0.5000 - accuracy: 0.8614 - val_loss: 0.4493 - val_accuracy: 0.8820\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.43838\n",
            "Epoch 81/125\n",
            "703/703 - 31s - loss: 0.4998 - accuracy: 0.8611 - val_loss: 0.5094 - val_accuracy: 0.8686\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.43838\n",
            "Epoch 82/125\n",
            "703/703 - 31s - loss: 0.4963 - accuracy: 0.8626 - val_loss: 0.4754 - val_accuracy: 0.8774\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.43838\n",
            "Epoch 83/125\n",
            "703/703 - 31s - loss: 0.4966 - accuracy: 0.8624 - val_loss: 0.4852 - val_accuracy: 0.8718\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.43838\n",
            "Epoch 84/125\n",
            "703/703 - 31s - loss: 0.4974 - accuracy: 0.8604 - val_loss: 0.5053 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.43838\n",
            "Epoch 85/125\n",
            "703/703 - 31s - loss: 0.4975 - accuracy: 0.8626 - val_loss: 0.5008 - val_accuracy: 0.8700\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.43838\n",
            "Epoch 86/125\n",
            "703/703 - 31s - loss: 0.4940 - accuracy: 0.8637 - val_loss: 0.4459 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.43838\n",
            "Epoch 87/125\n",
            "703/703 - 31s - loss: 0.4931 - accuracy: 0.8623 - val_loss: 0.4873 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.43838\n",
            "Epoch 88/125\n",
            "703/703 - 31s - loss: 0.4921 - accuracy: 0.8630 - val_loss: 0.4845 - val_accuracy: 0.8766\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.43838\n",
            "Epoch 89/125\n",
            "703/703 - 31s - loss: 0.4950 - accuracy: 0.8623 - val_loss: 0.4664 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.43838\n",
            "Epoch 90/125\n",
            "703/703 - 31s - loss: 0.4910 - accuracy: 0.8630 - val_loss: 0.4503 - val_accuracy: 0.8876\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.43838\n",
            "Epoch 91/125\n",
            "703/703 - 31s - loss: 0.4909 - accuracy: 0.8637 - val_loss: 0.4542 - val_accuracy: 0.8872\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.43838\n",
            "Epoch 92/125\n",
            "703/703 - 31s - loss: 0.4928 - accuracy: 0.8630 - val_loss: 0.4644 - val_accuracy: 0.8804\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.43838\n",
            "Epoch 93/125\n",
            "703/703 - 31s - loss: 0.4894 - accuracy: 0.8644 - val_loss: 0.4802 - val_accuracy: 0.8748\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.43838\n",
            "Epoch 94/125\n",
            "703/703 - 31s - loss: 0.4903 - accuracy: 0.8632 - val_loss: 0.5282 - val_accuracy: 0.8548\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.43838\n",
            "Epoch 95/125\n",
            "703/703 - 31s - loss: 0.4864 - accuracy: 0.8647 - val_loss: 0.5035 - val_accuracy: 0.8726\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.43838\n",
            "Epoch 96/125\n",
            "703/703 - 31s - loss: 0.4932 - accuracy: 0.8629 - val_loss: 0.4752 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.43838\n",
            "Epoch 97/125\n",
            "703/703 - 31s - loss: 0.4852 - accuracy: 0.8665 - val_loss: 0.4500 - val_accuracy: 0.8858\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.43838\n",
            "Epoch 98/125\n",
            "703/703 - 31s - loss: 0.4873 - accuracy: 0.8648 - val_loss: 0.4638 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.43838\n",
            "Epoch 99/125\n",
            "703/703 - 31s - loss: 0.4867 - accuracy: 0.8649 - val_loss: 0.4799 - val_accuracy: 0.8766\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.43838\n",
            "Epoch 100/125\n",
            "703/703 - 31s - loss: 0.4848 - accuracy: 0.8663 - val_loss: 0.5072 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.43838\n",
            "Epoch 101/125\n",
            "703/703 - 31s - loss: 0.4862 - accuracy: 0.8653 - val_loss: 0.4664 - val_accuracy: 0.8778\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.43838\n",
            "Epoch 102/125\n",
            "703/703 - 31s - loss: 0.4872 - accuracy: 0.8646 - val_loss: 0.4619 - val_accuracy: 0.8860\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.43838\n",
            "Epoch 103/125\n",
            "703/703 - 31s - loss: 0.4823 - accuracy: 0.8687 - val_loss: 0.4452 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.43838\n",
            "Epoch 104/125\n",
            "703/703 - 31s - loss: 0.4852 - accuracy: 0.8670 - val_loss: 0.5115 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.43838\n",
            "Epoch 105/125\n",
            "703/703 - 31s - loss: 0.4849 - accuracy: 0.8657 - val_loss: 0.4343 - val_accuracy: 0.8948\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.43838 to 0.43426, saving model to model.125epochs.hdf5\n",
            "Epoch 106/125\n",
            "703/703 - 31s - loss: 0.4851 - accuracy: 0.8673 - val_loss: 0.4543 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.43426\n",
            "Epoch 107/125\n",
            "703/703 - 31s - loss: 0.4802 - accuracy: 0.8698 - val_loss: 0.4564 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.43426\n",
            "Epoch 108/125\n",
            "703/703 - 31s - loss: 0.4863 - accuracy: 0.8662 - val_loss: 0.4962 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.43426\n",
            "Epoch 109/125\n",
            "703/703 - 31s - loss: 0.4819 - accuracy: 0.8696 - val_loss: 0.4423 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.43426\n",
            "Epoch 110/125\n",
            "703/703 - 31s - loss: 0.4829 - accuracy: 0.8653 - val_loss: 0.4981 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.43426\n",
            "Epoch 111/125\n",
            "703/703 - 31s - loss: 0.4843 - accuracy: 0.8659 - val_loss: 0.5442 - val_accuracy: 0.8592\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.43426\n",
            "Epoch 112/125\n",
            "703/703 - 31s - loss: 0.4783 - accuracy: 0.8707 - val_loss: 0.4883 - val_accuracy: 0.8726\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.43426\n",
            "Epoch 113/125\n",
            "703/703 - 31s - loss: 0.4830 - accuracy: 0.8668 - val_loss: 0.4656 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.43426\n",
            "Epoch 114/125\n",
            "703/703 - 31s - loss: 0.4744 - accuracy: 0.8699 - val_loss: 0.5296 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.43426\n",
            "Epoch 115/125\n",
            "703/703 - 31s - loss: 0.4757 - accuracy: 0.8687 - val_loss: 0.4394 - val_accuracy: 0.8862\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.43426\n",
            "Epoch 116/125\n",
            "703/703 - 31s - loss: 0.4832 - accuracy: 0.8650 - val_loss: 0.4528 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.43426\n",
            "Epoch 117/125\n",
            "703/703 - 31s - loss: 0.4764 - accuracy: 0.8705 - val_loss: 0.4725 - val_accuracy: 0.8850\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.43426\n",
            "Epoch 118/125\n",
            "703/703 - 31s - loss: 0.4831 - accuracy: 0.8683 - val_loss: 0.4676 - val_accuracy: 0.8782\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.43426\n",
            "Epoch 119/125\n",
            "703/703 - 31s - loss: 0.4788 - accuracy: 0.8687 - val_loss: 0.4596 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.43426\n",
            "Epoch 120/125\n",
            "703/703 - 31s - loss: 0.4764 - accuracy: 0.8697 - val_loss: 0.4541 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.43426\n",
            "Epoch 121/125\n",
            "703/703 - 31s - loss: 0.4731 - accuracy: 0.8711 - val_loss: 0.4744 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.43426\n",
            "Epoch 122/125\n",
            "703/703 - 31s - loss: 0.4801 - accuracy: 0.8674 - val_loss: 0.4794 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.43426\n",
            "Epoch 123/125\n",
            "703/703 - 31s - loss: 0.4755 - accuracy: 0.8715 - val_loss: 0.4485 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.43426\n",
            "Epoch 124/125\n",
            "703/703 - 31s - loss: 0.4730 - accuracy: 0.8729 - val_loss: 0.4330 - val_accuracy: 0.8926\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.43426 to 0.43300, saving model to model.125epochs.hdf5\n",
            "Epoch 125/125\n",
            "703/703 - 31s - loss: 0.4748 - accuracy: 0.8692 - val_loss: 0.4326 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.43300 to 0.43256, saving model to model.125epochs.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6wtuMx0ZzY2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qngg_3MEUcl",
        "outputId": "6a31fba6-b40f-4e10-de80-c1ad52047b26"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size =128, verbose=1)\n",
        "print('\\nTest result: %.3f loss:%.3f' %(scores[1]*100,scores[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 13ms/step - loss: 0.4804 - accuracy: 0.8777\n",
            "\n",
            "Test result: 87.770 loss:0.480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Eq9emEzIFGlO",
        "outputId": "27256b3b-307e-452e-b285-fc8249cd76f9"
      },
      "source": [
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c+TSe+dkgAJECkiUqJSBEFEQV1xV9cFdcXVXeztq36VVdeVLV9/W2y7uorY1t4VFRULNoqQIC3UUJPQQgpJSJ+c3x9nAkMIMECSmUye9+s1r8y999y5z52BZ86ce+45YoxBKaWU/wrwdgBKKaValyZ6pZTyc5rolVLKz2miV0opP6eJXiml/FygtwNoKjEx0aSlpXk7DKWUaleys7P3GGOSmtvmc4k+LS2NrKwsb4ehlFLtiohsPdw2bbpRSik/p4leKaX8nCZ6pZTyc5rolVLKz2miV0opP6eJXiml/JwmeqWU8nOa6JVSygvqnQ1kbSnmxfmb2V1W3arH8rkbppRSyhu2Fu1jV1kNp6fHH7S+ocEQECCHlK+pd5K9tYTMHvEEBx5aZzbGsLGwgm/WFeJsMEwdkUZokIOGBsMTX2/g+R82U1ZdD8C/5+Xy6K8GMSqj2RtbT5gmeqVUu7J+VzkFpVUM75lAaJDjkO11zgbezc7nqW820q9LFA//YiBxEcEszytlxserObtvMjeO6YXIgeS9PK+Uq55fzN6qOqaN7sn/nteHpdtKuf+DlRSUVDGkRxzDeyUwdXgaESGBOBsMt7z2E3NX7yI5KoQrh/Wgb+coyqrr2VVWzfK8Upbnl7KrrGb/MT5ctp2/XTqQx7/awBerd3HeyZ246NQUusaGcs+7K7jq+cXcOKYXd47v0+wXy4kQX5thKjMz0+gQCEr5t4qaetbsKGNgagwhgQcn6zpnA2t3lJMUFUKn6JCDEvJbS/K474OV1DkNkSGBjOuXzNg+yYzsncjeqjo+z9nJW1l5bC2qpG/nKDYV7iM+IpgJAzrz8qKthAQGUFnr5JIhqfzfL04hODCAxZuLuebFJcRFBDGiZyJvZuWRlhDOlqJKUmLDOKtPEtlbSli3q5yeSRE8efkQ/rtwK68v3sa1Z6azYXcF360vPOgc0hLCGZgay7CeCYw+KZH1u8q5863llFTW4QgQHrigH1NHpO0/t6paJ3+cnUN1vZPHfjXooHP2lIhkG2Mym92miV4p1VKKKmpYvaOMPp2iSI4OxdlgWJZXysbdFYw+KYnOMaEs3VbCbW/8RF5xFVEhgZzTvxOdY0KpqWsgr6SShRuLqKixTRoJEcH06xJN7+RI9tXU83Z2Pmf2TuTqEWnMXb2TL1bvoqSy7qAYhnSP5cYxvRnXL5mc7WXc8vpPbN6zj58PTuGPPzuZFxZs5rEvN9AlJpTKWid7q+romRTBq789gy4xYXy4rIA/f7KGnw9O4fZzMggPtg0fCzcWcesbP1FUUUODgRvH9OJ/J/QFYFtRJXur6ogOCyQ+Ipio0KBD3psde6t47IsNXDSoKyN7Jzb7/tU7Gwh0HN+lU030SnVQtp14H1lbigEIDgygf9do+naOBqC2voHPcnaycGMRK/JL2VNRw7CeCYzKSMLZ0EDu7grKq+tJT4ygR0IERftq2Lh7H1uK9pFXXMnOsmoSI0NIjQujpLKWVQVl+4/dPT6cipp6ivfVAiACQ7rHsSyvlC4xodw6LoOsLcXMXb2LyhonIYEBxEcGM7J3IsN6JlCyr5ZVBXtZv6ucjYX7qKip5+oRadx/Qb/9ydDZYMjZvpcfcvcQERzIuSd3oktM2EHvQWVtPbm7KxiYGrt/3ezl2/lo+XY6R4fSLT6MS4akkhAZctT3c09FDfe/v4qUuDDuv6DfcdW8W4smeqV8XFl1HSvz97KtuJKM5Ej6d43eX5MEe+HvuR82YwwM7hbLKakx+2uNWVuK+fvn61iRv5fI0ECiQwOJDgsiOjSIrUX72FJUecjxhvaI44z0eN5bWsDOsmqiQwMZmBpLXEQwC3L3UORKzsGBAUQEOw6qNYcFOeiREE73+HA6x4RSVFFLXkklYUEORmUkMjA1lvW7ysnaUkJ4sIMxfZPpnRTJ5zk7+WzVTgakxPDgRf2JbqbWezjGGCprnUSE6GXFw9FEr9QJMsbw3tICUuLCGNYz4bhfZ8feKgJE6BQdCsC6neX8cXYOizYX4f5fMUBgfP9OTJ/Yj+iwIK5/OZvFrlp5oy4xoSRGhrCyYC9JUSFccEoXauptU0RZVT17q+pIiAzm7L7JjMpIIiQwgKo6J/PW7uaVRVvZUlTJiF4J/G50T87KSNp/AbChwbB+dznhQYGkxIXhCBBKK2vZVlxJQmQIXaJDW/xioTpxmuiVcmn8936kn9z1zgamv7cSR4Dw+wv6ERUSyD/mruPJeRsB+N2odP5nfB9+2lbCZzk72VpUSWF5Dftq6wkLchAZEsiYPkn86rTuxIUHsXBTEXNW7mTBxj1sddWuh/aIIyM5kney84kKDeTXw9MY2iOOtIRw1u+qIGtLMS8v2kqds4G48GBKq+r4xy9PZXRGIsvySsnZXkbu7gryiisZ2zeZ34xMO+gXwNE0NBhKKms9aq5Q7cMJJ3oRmQA8DjiAWcaYh5ts7w68BMS6ytxrjJkjImnAGmCdq+giY8z1RzqWJnrVkmrqnXy2aifv/1TA5j372LG3msSIYKaf348LB3Zh+95qXlqwhWBHADeN7U1oUAAPfLiKVxZtI0CgS0wYI3ol8HZ2PpNP60agQ3hl0TaCHQHUOhsID3bQOzmS5KgQIkICqap1UlhRw0/bSglyCNGhQRTtqyUyJJBhPRMY3iuBqtp6Pl6xg7U7y/nl0FSmn9+P+IjgQ2LfXVbNP+auY8mWEv552akM6R7nhXdQtRcnlOhFxAGsB8YD+cASYIoxZrVbmZnAT8aY/4hIf2COMSbNleg/NsYM8DRYTfTqWJVW1vLJyh3k7q5gbJ9kRvRKYFtxJW8uyeOd7HyK9tXSLT6Mwd3i6BwTyvzcPeRsL6Nv5yhyd1cAUN9g6JkYweiTknhxwRauO6sn5/bvzB1vLmNbcSVXDuvOjIsGEBAgfLVmF1+u2cWojCTG9kkmLPjQvtwbCyt4ddE29lTUcP4pnRnTJ/mQPt/Vdc5m+4ErdTyOlOg9+a13OpBrjNnkerE3gEnAarcyBoh2PY8Bth9/uEpZxhheX5zHv7/eQEpcGIO7x9EpOhRjDNV1TgpKq9i8Zx/ZW0uocxqCHMIL87cQFRpIeXU9jgBhXN9krhzWgzN7J+5vV3Y2GF5fvI2XF27lymE9+N3onmzds487317Oiwu2cMHALtxzXl8CAoQ5t40ie2sJozMS9zf3jOvXiXH9Oh0x9l5JkfzhZ/2PWEaTvGorntToLwUmGGN+61r+NXCGMeZmtzJdgLlAHBABnGOMyXbV6HOwvwjKgPuNMd8f6Xhao++Y9lTUsLJgLxt3V9ApOpReSZE898Nm3l2az+DusRgDq7eXUets2L9PYmQwqXHhnJYWx6RBKfROjuSbdYV8uWYX6YkR/HJoKsmui56e2FtVxxerd3HhwC6ahFW7c6I1ek9MAV40xvxTRIYDL4vIAGAH0N0YUyQiQ4EPRORkY0yZ+84iMg2YBtC9e/cWCkn5iuo6J/Nz91BRU09IYACllXUs3lLMT9tKKamsparWSU19wyH7icBt4zK4dVwGjgChtr6BqjonAQJBjoBmk/GEAZ2ZMKDzccUZExbEpUNTj2tfpXyZJ4m+AOjmtpzqWufuWmACgDFmoYiEAonGmN1AjWt9tohsBE4CDqqyG2NmAjPB1uiP4zyUF9XUO1m8uZiVBXsJCXQQEeygwdgbVTYW7uOTFdv3D97UKCEimMw02xQTFuQgMTKEASkxnNQpkl1lNazfVU73hPCDLkAGBwY0O3iUUurIPEn0S4AMEUnHJvjJwOVNymwDxgEvikg/IBQoFJEkoNgY4xSRnkAGsKnFoldtyhhDVZ2Tkso6du6tJmtLMT9uLmbRpiIqa53N7hMW5GDCgM5cPDiF1LgwauoaCAt2kJYQftgujgmRIfTvGt3sNqXUsTtqojfG1IvIzcDn2K6TzxtjckRkBpBljJkN3Ak8KyJ3YC/MXm2MMSIyGpghInVAA3C9Mab4MIdSPsIYw7tLC8grruTaUelEhwaxraiSO95aRvbWkoPK9kyK4JIhqYzpk8Rp6fEYA/tq7IXQ0CBbuz/esTuUUi1Db5jqYL5bX8ijX66norqeWmcDmT3imTqix/5xQPJLKpn+3kq+37AHsE0slw5N5dUfbb/ya8/sSafoEBIiQzi1WwzJUZ5f7FRKtZ62uBir2oGc7Xu5/pVskqJC6N/FNo18tmoH7y7Np1N0CJU1Tspr6gkPdvCnSSczMDWWP328mme+28RpaXE8NnkwKbFhRzmKUsrXaKL3M8YY5ucWUVPvZFjPhP2DQO0qq+baF7OICQvi7euG7+92WF5dx7vZ+azI30t0WBCJkcFMGpRCt/hwAN6+fvj+YWe1CUap9kkTvZ+oczbw8YrtPP3NJtbtKgcgyCH07RxNnbOBHXurqXc28Pb1Iw7qWx4VGsTVI9MP+7oiwsldY1o9fqVU69FE385V1tbzbnY+T3+7iYLSKvp0iuLRX51KclQo320oJKegjPBgBwNSYvjVad20N4tSHZAmeh9mjGHNjnK+XLMLR4Ad2tYRAAUlVWwrrmRlQRnrd5XjbDAM6R7LjEknc3bf5P3dFg83i41SqmPRRO+DGhoM7y7N59nvN7F+V0WzZRIjQ+jXJYpxfXsx+qQkTkuL86nZbpRSvkMTvQ+Y9f0mnv52E6MzEhnZO5HXFm8je2sJp6TE8KeLB3DBKV0IC3Kwu7ya+gZDSmyYjsWilPKYJnoveyc7nz9/sob+XaL5et1u3vupgPiIYP526UAuHZJ60Ew+PRIivBipUqq90kTfyor31RIXHnRQs8reyjr27Kth2bZS7nl3BSN7J/D81acRIMKqgr30TIwkJtzz+TSVUupINNG3oney87nr7eUkR4UwolcCDQayt5ZQUFq1v8zJXaN5+sqhhATappjBOouQUqqFaaJvJau3l3Hf+ysZ3D2W1LhwfsgtwhHA/iEHOkWHEh8RTGaP+GZnKFJKqZaiib4V7K2q44ZXs4kND+LZqzJJ1AmYlVJepIm+BVXXOflo+XZmfb+ZgpIq3rxumCZ5pZTXaaI/DuXVdTzyxXoKSqqorm9gX009pZW17CqroaKmnozkSP59+RCG9oj3dqhKKaWJ/lgVltfwmxcXs2ZHORnJkYS4xlzv2zmaEb2CmTigM8N7JejNS0opn6GJ/hjkFVdy5XM/srushllTMxnbJ9nbISml1FF5NO6siEwQkXUikisi9zazvbuIzBORn0RkhYic77Ztumu/dSJyXksG35Z2l1VzxawfKa2s49XfnaFJXinVbhw10YuIA3gSmAj0B6aISP8mxe4H3jLGDMbOKfuUa9/+ruWTsZOHP+V6PZ+1t6qO6jrnIeumvrCEPRU1vHTN6QdNWK2UUr7Ok6ab04FcY8wmABF5A5gErHYrY4DG8W9jgO2u55OAN4wxNcBmEcl1vd7CFoi9xe2tquOcR77FIcJd5/XhZ6d24Zt1hTw5L5fc3eU8N/U0BnWL9XaYSil1TDxJ9ClAnttyPnBGkzJ/BOaKyC1ABHCO276Lmuyb0vQAIjINmAbQvXt3T+JuFU/Ny2VPRQ19O0dz19vL+f17K6l1NpAYGcLjkwcz+qQkr8WmlFLHq6Uuxk4BXjTG/FNEhgMvi8gAT3c2xswEZoKdHLyFYjom24oqeWH+Fi4ZksrfLhnIRyu2s2hTMeP7JzM6I0mn0VNKtVueJPoCoJvbcqprnbtrsW3wGGMWikgokOjhvj7h/322FkeAcNe5fQgIECYNSmHSoEN+fCilVLvjSTV1CZAhIukiEoy9uDq7SZltwDgAEekHhAKFrnKTRSRERNKBDGBxSwXfEuqdDTz/w2Y+WbmD687qSeeY0KPvpJRS7chRa/TGmHoRuRn4HHAAzxtjckRkBpBljJkN3Ak8KyJ3YC/MXm2MMUCOiLyFvXBbD9xkjHE2f6S2tzyvlHvfW8maHWWMykhk2uie3g5JKaVanNh87DsyMzNNVlZWqx9nT0UN4/75LeHBDh64sD8TB3TWu1mVUu2WiGQbYzKb29Zh74z9yydrqKyt590bRtA7OdLb4SilVKvpkF1J5ufu4f2fCrj+rF6a5JVSfq/D1Oj/OmcNP2zYw8ldo/lxczE9EsK5aWxvb4ellFKtrkPU6Ofn7mHmd5twNhi+Xrub/JJK/nLxKYQG+fRoDEop1SL8vkZfXefkvvdXkpYQzoc3jyQkMIDqugadvk8p1WH4faL/19cb2FJUyau/PWN/DV6TvFKqI/Hrppvc3eU88+0mfjEkhZG9E70djlJKeYVfJ/o/f7KGsCAH953fz9uhKKWU1/htov9m3W6+WVfIreMySNAJupVSHZhfJvp6ZwN//mQNaQnhTB2R5u1wlFLKq/wy0b++eBu5uyv4/fn9CA70y1NUSimP+V0WrKl38u95uZyeFs/4/p28HY5SSnmd3yX6d7ML2FVWwy3jeusgZUophZ8l+npnA09/u5FTU2M4U7tTKqUU4GeJ/qMV29lWXMlNY7U2r5RSjfwm0Tc0GJ6at5E+naI4p5+2zSulVCOPEr2ITBCRdSKSKyL3NrP9URFZ5nqsF5FSt21Ot21NpyBsMXkllZRU1nHj2F4EBGhtXimlGh11rBsRcQBPAuOBfGCJiMw2xqxuLGOMucOt/C3AYLeXqDLGDGq5kJvXIyGCH+4ZS6AmeaWUOognNfrTgVxjzCZjTC3wBjDpCOWnAK+3RHDHKjTIQaDDb1qjlFKqRXiSFVOAPLflfNe6Q4hIDyAd+NptdaiIZInIIhG5+DD7TXOVySosLPQw9CbKdsAjJ8Myr3zHKKWUz2rp6u9k4B1jjNNtXQ/XhLWXA4+JSK+mOxljZhpjMo0xmUlJScd35IhEKN8BxRuPb3+llPJTniT6AqCb23Kqa11zJtOk2cYYU+D6uwn4hoPb71uOIwhiUqF4c6u8vFJKtVeeJPolQIaIpItIMDaZH9J7RkT6AnHAQrd1cSIS4nqeCIwEVjfdt8XEp0OJJnqllHJ31ERvjKkHbgY+B9YAbxljckRkhohc5FZ0MvCGMca4resHZInIcmAe8LB7b50WF5euNXqllGrCo6kEjTFzgDlN1v2hyfIfm9lvAXDKCcR3bOLToaoYqvdCaEybHVYppXyZf/VFjEuzf7VWr5RS+/lZok+3f7WdXiml9vOvRB/fmOi3eDUMpZTyJf6V6EOiIDxRm26UUsqNfyV60C6WSinVhP8l+rh0KN7i7SiUUspn+F+ij0+Hsnyor/V2JEop5RP8L9HHpYNpgNJt3o5EKaV8gv8l+njtYqmUUu78L9E39qXXnjdKKQX4Y6KPTIagcK3RK6WUi/8lehE7FILW6JVSCvDHRA+uLpabvB2FUkr5BP9M9F1OhT3roarU25EopZTX+Wei7zECMLBtkbcjUUopr/PPRJ+aCY5g2Drf25EopZTXeZToRWSCiKwTkVwRubeZ7Y+KyDLXY72IlLptmyoiG1yPqS0Z/GEFhUHKUE30SimFBzNMiYgDeBIYD+QDS0RktvuUgMaYO9zK34JrAnARiQceBDIBA2S79i1p0bNoTo+R8MOjUFMBIZGtfjillPJVntToTwdyjTGbjDG1wBvApCOUnwK87np+HvCFMabYldy/ACacSMAe6zECjBPyF7fJ4ZRSyld5kuhTgDy35XzXukOISA8gHfj6WPYVkWkikiUiWYWFhZ7EfXTdTgdxwBZtvlFKdWwtfTF2MvCOMcZ5LDsZY2YaYzKNMZlJSUktE0lIFHQdBFsXtMzrKaVUO+VJoi8Aurktp7rWNWcyB5ptjnXfltdjBBRkQV1Vmx1SKaV8jSeJfgmQISLpIhKMTeazmxYSkb5AHLDQbfXnwLkiEiciccC5rnVto8eZ4KyF/Kw2O6RSSvmaoyZ6Y0w9cDM2Qa8B3jLG5IjIDBG5yK3oZOANY4xx27cY+BP2y2IJMMO1rm30GA4SAJu/bbNDKqWUrxG3vOwTMjMzTVZWC9bAZ423E5H87quWe02llPIxIpJtjMlsbpt/3hnrrtdY2L4Uqlq/675SSvki/0/0PcfaGv3m770diVJKeYX/J/rUTAiOgo1fH72sUkr5If9P9I4gSDsTNs3zdiRKKeUV/p/owbbTl2w5MOuUs96r4SilVFvqIIn+bPt36Uvw1lT4SyfYtfrI+yillJ846uiVfiGhN0Sn2tEsg8KhoR5yv4RO/b0dmVJKtbqOUaMXgbHT4Ywb4NafIL6nzj6llOowOkaNHmDwlQeedx8B6+aAMfZLQCml/FjHqNE31X0YVBXDng3ejkQppVpdB030w+3fbQuPXE4ppfxAx0z0Cb0gPFHb6ZVSHULHTPQitvlmm05KopTyfx0z0YNtvinZAmU7vB2JUkq1qo6d6AHytPlGKeXfPEr0IjJBRNaJSK6I3HuYMpeJyGoRyRGR19zWO0VkmetxyMxUXtNloL15SueUVUr5uaP2oxcRB/AkMB7IB5aIyGxjzGq3MhnAdGCkMaZERJLdXqLKGDOoheM+cY4g6H0OLHsdRt0JUZ29HZFSSrUKT2r0pwO5xphNxpha4A1gUpMyvwOeNMaUABhjdrdsmK3knD+Cswa+fMjbkSilVKvxJNGnAHluy/mude5OAk4SkfkiskhEJrhtCxWRLNf6i5s7gIhMc5XJKiwsPKYTOCEJvWD4TbD8Nchb3HbHVUqpNtRSF2MDgQxgDDAFeFZEYl3berjmMbwceExEejXd2Rgz0xiTaYzJTEpKaqGQPDTqLojqAnPuhoaGtj22Ukq1AU8SfQHQzW051bXOXT4w2xhTZ4zZDKzHJn6MMQWuv5uAb4DBJxhzywqJhHF/gB3LYMt33o5GKaVanCeJfgmQISLpIhIMTAaa9p75AFubR0QSsU05m0QkTkRC3NaPBHxvIPj+F0NQBKx6z9uRKKVUiztqojfG1AM3A58Da4C3jDE5IjJDRC5yFfscKBKR1cA84G5jTBHQD8gSkeWu9Q+799bxGcHh0Pd8WDMbnHXejkYppVqUGGO8HcNBMjMzTVZWVtsfeO0ceGMKXPEuZJzT9sdXSqkTICLZruuhh+i4d8Y21XschMRAjjbfKKX8iyb6RoEh0PcCWPMx1Nd4OxqllGoxHWeGKU8M+IXtU//ZdKgsspOTnD4N+lwAAfqdqJRqnzR7ues5BiKSIes5KMiGkq3w5pUwczTsyvF2dEopdVy0Ru/OEQTXfQumAWJSwVkPq96Fz6fD57+Hqz70doRKKXXMNNE3Fd31wHNHIJz6KygrgK8esrX6Tid7LzallDoO2nTjiaFX2yGNFz7l7UiUUuqYaaL3RHg8nDoFVr4FFe1jYE6llGqkid5Tw24EZy0sec7bkSil1DHRRO+pxN5w0gRYMgvqqrwdjVJKeUwT/bEYfjNU7oHlb3g7EqWU8pgm+mORdiZ0GQQL/61j1yul2g1N9MdCBEbeCkW5sP5Tb0ejlFIe0X70x6rfJIjtDvOfgK5DYOlLdv1Z99gvAqWU8jGa6I+VIxCG3QSf3QOPngzGadcHOGD03d6NTSmlmqFNN8dj8JXQaxyccT3cshQG/gq+/jPkvO/tyJRS6hAeJXoRmSAi60QkV0TuPUyZy0RktYjkiMhrbuunisgG12NqSwXuVSGR8Ov3YMJfIaEXXPQv6DYM3r/eTkfoY5O5KKU6tqMmehFxAE8CE4H+wBQR6d+kTAYwHRhpjDkZuN21Ph54EDgDOB14UETiWvQMfEFgCEx+FZL7wzu/sSNelu/ydlRKKQV4VqM/Hcg1xmwyxtQCbwCTmpT5HfCkMaYEwBjTOE7AecAXxphi17YvgAktE7qPiUiEa7+A8TMg90t4YQLUlHs7KqWU8ijRpwB5bsv5rnXuTgJOEpH5IrJIRCYcw76IyDQRyRKRrMLCQs+j9zWOQBh5G/z6fSjZAp/e4+2IlFKqxS7GBgIZwBhgCvCsiMR6urMxZqYxJtMYk5mUlNRCIXlRjxEw6i5Y9qodz14ppbzIk0RfAHRzW051rXOXD8w2xtQZYzYD67GJ35N9/dNZ/wspmfDRHVCw1NvRKKU6ME8S/RIgQ0TSRSQYmAzMblLmA2xtHhFJxDblbAI+B84VkTjXRdhzXev8nyMILpkFodHw/Hnw40ztjaOU8oqj3jBljKkXkZuxCdoBPG+MyRGRGUCWMWY2BxL6asAJ3G2MKQIQkT9hvywAZhhjilvjRHxSfDpc9x18cAN8ejf88CiExkBkEgyZCv0vtu36SinVisT4WC0zMzPTZGVleTuMltXQANkvQH4W1JbDrtVQvBHi0uCCR6D3OG9HqJRq50Qk2xiT2ew2TfRe0NAA6+bAVzPsfLS/+xqS+ng7KqVUO3akRK9DIHhDQAD0u9B2wwwKszdYNfa5r6/VtnylVIvSRO9NMSlw6QtQtBFe+hk8PQr+0gm+fNDbkSml/Igmem9LHwUT/g+KN0FYLKSPhvmPQ+5X3o5MKeUntI3e19RVwcyxUFUMNyywQysopdRRaBt9exIUZvvfV5XCO9fA3nxvR6SUauc00fuizgPggn/A1gXwxGCYczfsK/J2VEqpdkoTva8achXcuhROnQJZz8NTw2B9x7ipWCnVsrSNvj3YuQremwa7c6DnGIjsBGFxMOwGe9OVUqrD0zb69q7zAJg2D878H6gohLwfIftFe9F283fejk4p5eO0Rt9eFW2E16dAUS6M/T2ccR2ERHk7KqWUlxypRq8jarVXCb3gt1/aAdO+/hPMfwIGXwExqeAIhsSToMdIHTRNKaWJvl0LjbZz1eZnw4In4MenwTQc2B6RBOln2T75e/Nh6NUw/CavhauU8g5N9P4gdShc9hLU19gbruprYNtCyHnfdtGM6gQSAF/+ETLOg8Te3o5YKdWGNNH7k8AQ+wA4+WL7aFS+C/59GmvnXHcAABbcSURBVHzyP3DVhyDinRiVUm1Oe910FFGdYNwDsPlbncdWqQ7Go0QvIhNEZJ2I5IrIvc1sv1pECkVkmevxW7dtTrf1TacgVG0p8xroOhg+mw7Ve70djVKqjRw10YuIA3gSmAj0B6aISP9mir5pjBnkesxyW1/ltv6ilglbHZcAB1z4KOwrhG8ePnR7fS0UrgdnfdvHppRqNZ7U6E8Hco0xm4wxtcAbwKTWDUu1mq6DIfM38OMzsCvHrlvzETw/ER7uBk+eBq9eemAiFKVUu+dJok8B8tyW813rmrpERFaIyDsi0s1tfaiIZInIIhG5uJn9EJFprjJZhYWFnkevjs/ZD9hJyj+5Cz77vZ3hqnIPnPZbGHufvdv2xQvtGPmF6+1ct846b0etlDpOLdXr5iPgdWNMjYhcB7wEnO3a1sMYUyAiPYGvRWSlMWaj+87GmJnATLB3xrZQTOpwwuPhnAfho9tg2wI4/To4988QGGy3dzkV3ppqR85sFNsDRv0PnHr5gXJgvxRCY6HLwLY9B6WUxzxJ9AWAew091bVuP2OM+xi6s4C/uW0rcP3dJCLfAIOBgxK98oLBV9nhE1IyD+6GCXDSefau283f2ZuuABY9Zb8YfnwGLn8TYrvDynfgvd/ZMjdn2Ru4lFI+56hj3YhIILAeGIdN8EuAy40xOW5luhhjdrie/xy4xxgzTETigEpXTT8RWAhMMsasPtzxdKwbH2UMrJsD799g++oPux6+/gt06m9H1xx+E5z3F29HqVSHdUKjVxpj6oGbgc+BNcBbxpgcEZkhIo29aG4VkRwRWQ7cClztWt8PyHKtnwc8fKQkr3yYCPS9AH77BQSFwlczIGUo/OZTGPJrO/xC4TpvR6mUaoaOXqmOXUUhLHvVjp0TFgv79sC/hkBSPxh4GdRVQu/xkNzX25Eq1WEcqUaviV61jCWz4JM7DywHRdjxdzLGey8mpToQnXhEtb7Ma+H2lXDnOrh1mR1G+bVfweJnocFpyxhjp0Nc/Kx93mjVe7a9X7twKtUqdFAz1TJEbE+cRr+ZA29fDXPugh8eg1Mnw6ZvoMD1a61wLZz/D8h5D965FjB22y9f0t47SrUwTfSqdYREweVvwdqPYclz8P0/IDoVfvY47NkAC/8NpXmw8SvoMQIG/AI+vQeenwC/mGmnT1RKtYh2kejr6urIz8+nurra26G0utDQUFJTUwkKCvJ2KCcuwAH9J9lHRaG9Gzcw2DbbiMCCf0HXITDlDVuLj+9lfwU8faa9qHv2AxDb7aiHUUodWbu4GLt582aioqJISEhA/HgcdWMMRUVFlJeXk56e7u1wWpcxtjafepr9AmhUVQI/PGpvzAqJgt98phOlKOWBdn8xtrq62u+TPICIkJCQ0CF+uSACvc85OMkDhMXB+Blw3Xf2y+C/k2wTz44V8MGN8Oav4ft/Qu6XdnrEphWVBifkfmW7fB6rkq3wyiVQtuP4z0spH9Qumm4Av0/yjTrKeR5VUh/49ft2cLX/jISavRAcCRGJsMZtWoOgCEjNhJMm2C+N+Y/DnnW2GWjqRxDT3Ph7hzH/cfsFkvUcnH1/y5+TUl7SbhK96oC6DIQr3obP7oV+F9ounGGxtnln5yrYs97ejbv5O/h8ut0nqR+M/xN8+zd48Xyb7N17AzUyBnaugE4D7LWEymJY9prd9tOrcNa94ND/Hso/tIumG19QWlrKU089dcz7nX/++ZSWlrZCRB1E9zNg2jwYdadN8mCbd9JHwWnXwvl/g5sWwW3L4eo5cMMCGHmrnRe3sgSeO8/23XfX4LRz5z4zGj79X7su63mor4Kx90P5dluzV8pPaKL30OESfX39kWdjmjNnDrGxsa0VlmoUlwZpIyHA9U86dShc/bHtzfPaZfDONbDuU/tL4O2pNrF3GWTv6P3xGVg8E3qNgzNvh4hkWPpfr56OUi2p3f02feijHFZvL2vR1+zfNZoHf3byEcvce++9bNy4kUGDBhEUFERoaChxcXGsXbuW9evXc/HFF5OXl0d1dTW33XYb06ZNAyAtLY2srCwqKiqYOHEiZ555JgsWLCAlJYUPP/yQsLCwFj0X5abLQHtR94dH4bt/HDwp+nn/B2dcZ+/ebazVX/wUOIJg0OW262f5TojqfPzHX/Q0ZL9gXzM8AS54xN4xrFQb0xq9hx5++GF69erFsmXL+Pvf/87SpUt5/PHHWb9+PQDPP/882dnZZGVl8cQTT1BUVHTIa2zYsIGbbrqJnJwcYmNjeffddw8po1pYYAiMuRfu3gDXfgmXPGe7bA6/0bbNX/ocJJ4EnQfaGj3AkKvAOOGLP8DWBVBbefBr7tkAXzwIRUeYViH3K3ttISjM3iiWnw2f//7gMjrkg2oj7a5Gf7Sad1s5/fTTD+rr/sQTT/D+++8DkJeXx4YNG0hISDhon/T0dAYNGgTA0KFD2bJlS5vF2+GFxUG30+zDXWgMXP8DOGttl0+wte5Tp8Dy12HFmxASA9d+Dsn97EXcD2+GvEWw4AkYcAkMu9HOxdu4f9l2OyFLUl973SA43HYJ/WoGbPvRXndY8TbMvhnO+6u91qBUK2p3id5XRERE7H/+zTff8OWXX7Jw4ULCw8MZM2ZMs33hQ0JC9j93OBxUVVW1SazqKAJD7MPdz5+2vXcKsuDDm2xyv3aunUg9bxGM+wNUldrhHVa+DZ1OgZPOhYZ62DgP6qrs6J3B4fb1zrgeFv3HJvtzZ9jXdATZi8L11XbiFqVaiUdNNyIyQUTWiUiuiNzbzParRaRQRJa5Hr912zZVRDa4HlNbMvi2FBUVRXl5ebPb9u7dS1xcHOHh4axdu5ZFixa1cXSqVUQmQZ+JMPFvNuHPfxy+fBCST4aRt8O5f4I719i29wCHrbUvehrKd8CkJ+29AI2CI2D03bD1B/jvzyGqE9ySDf0vtk063z9y6PHzs+Ht38BTw+3NYY0KlsKCf2vTj/LYUWv0IuIAngTGA/nAEhGZ3cxMUW8aY25usm888CCQCRgg27VvSYtE34YSEhIYOXIkAwYMICwsjE6dOu3fNmHCBJ5++mn69etHnz59GDZsmBcjVS1uwCW21v7VQ3b5yvdsYgfb9HPatfbR0HCg109zhl5tL/JWFsPk1+2F3kueA0ewfe3gCHuBuGQrzL4FNn9rm42ME964Aq75zM7z+9+L7Q1kG+bCL1+0k70rdQSezBk7HPijMeY81/J0AGPM/7mVuRrIbCbRTwHGGGOucy0/A3xjjHn9cMdrbqybNWvW0K9fv2M4rfato51vu1C2HZ4cBt2HwRVvHf/rFG2E+ho7124jZ73t8rn2Y8i8xrbfi9iLyEOugi0/wOtT7K+L/Czb5DPsBtsMFJMKv3r14Ncr2mjvFQiOgMhOeuNXB3GksW48+ReQAuS5LecDZzRT7hIRGY2dSPwOY0zeYfY9hnvSlfIR0V3hlqxDx+Y5Vs11r3QEwqXPw+uTbf/+HmfCz/9z4I7ePhPh7Pvg6z9DWLy9PyCpD6SeDm9eCTPH2InZe46FLx6wk7g3iu0Bv3jWXgBWHVZLfdV/BLxujKkRkeuAl4CzPd1ZRKYB0wC6d2/mdnWlfEFkcuu9dmAITH7NdufsOeZA01CjUXdBSDT0GHmg7b/7GfZO4A9usBO8gB0PaOz9EJ8O1aX2usILE2HELfaLo6oESrfZ4SNKt9lfF8Zpxwqa8PCBu4+VX/Ek0RcA7oOCp7rW7WeMce80Pgv4m9u+Y5rs+03TAxhjZgIzwTbdeBCTUv4nKAx6j2t+m4htv28qMslO8LJklm2/H3WnvdDb6JRfwid3wfzHDqwLi7ddP3uOgcBQ20NoxZuw+Xs7MUzamRAUevBx9myAhU/CKZfa7apd8STRLwEyRCQdm7gnA5e7FxCRLsaYxrFdLwLWuJ5/DvxVROJcy+cC0084aqXUAQEBcMa05reFxsAlz8K4ByAgyNbYg5q5G/u039q+/69eAuKwTUydB0LKUNibZ4eIaKi3Q0OMn2G7gzbeN1C+y16sDo6w1xSa/hpp1OCEj++wM4qdOrllzl155KiJ3hhTLyI3Y5O2A3jeGJMjIjOALGPMbOBWEbkIqAeKgatd+xaLyJ+wXxYAM4wxxa1wHkqpI2luBE93qUPh+u/tAHC718CuHNi2EFa9A4hN4Gfebu8WnnufHU4iMtk2/Wz+zjb/gL3JbNKTIAH2dZL7Hbgu8d3fYelLsOIte1E7Lq01z1i5aRczTHW0Xigd7XyVDyvfae8abvyiMMY24ayZbZt8Gpy2uWnwr2H7T/Dp3VC998D+gaFw4WN2SsiXfmavBWz+DroPt0NQ6/wLLeZEe90o7OiVr732GjfeeOMx7/vYY48xbdo0wsPDWyEypVpR00HdRGDEzfbRVNJJdvjoZa9CVBeI7wnz/gofXG8niIlLtxO/L33Zzh+w9L9QU27LmwaI6WZ/AZw6xXYXbXBCQTZsnQ/bl9kmpDHTIWP8sZ1DVQnkLYaMczvsF4vW6D20ZcsWLrzwQlatWnXM+zaOYJmYmOhReV84X6VahLPe3gz20yt2xrCug+y6WWfDjuW2TLczIDwR9m6D3Wuhoc4OKVGWb5M02G6iYO86vuxlOw1l1nN2CIrAEDs6aEAg1FXaawXn/902DdXX2FnK8hfbG9bO/+fB9xWU7YC8H6HX2BPvOutl/lWj//Re2LmyZV+z8ykw8eEjFnEfpnj8+PEkJyfz1ltvUVNTw89//nMeeugh9u3bx2WXXUZ+fj5Op5MHHniAXbt2sX37dsaOHUtiYiLz5s1r2diV8mWOQDtUxPgZB2rTjkD4xSxY9ortFdT5lAPl9+2xPYBWfwgZ59nxg9LHQESCTfr/vdjeOxCfbruIdjsDQmOhco9tVgoKt4n7hQtg6mw7tET+Yuh7IWS/aF+/7wV2GImtC2B3jj1u2ij7ReQIguLN9pfIWfccOjG9MfDpPRCRBGfdbdc1OOGTO+0vmBG3+OSvhvaX6L3k4YcfZtWqVSxbtoy5c+fyzjvvsHjxYowxXHTRRXz33XcUFhbStWtXPvnkE8COgRMTE8MjjzzCvHnzPK7RK+V3mia/pJNs8m8qItH26GlukLewODtz2KuXQsUuW7Pv97NDX3vnSjup/DOjobbCJuyxv7cTzHx6j70DOTgSUobAOQ/ZXkJz77fJetgN9sukYqd9XDX74Ndf/gYsfsY+T+5rj//d3+28A2AvYl/0xKGD5DUqWGrvgwiOaH57K2l/if4oNe+2MHfuXObOncvgwYMBqKioYMOGDYwaNYo777yTe+65hwsvvJBRo0Z5OVKl/ExYLFwz1z4/3LhCnU+xw0O/fLFt4jnLNQ7jGdfZewcAEjIO3r+qxA5Kt+It24Qz7EZY9BSs/cTOVwy2meeze6DbMDvi6Ic32WsM3zxsryvE94J5f4biTfbms9ShB8e15iP7a6TrELjy3TYdo6j9JXofYIxh+vTpXHfdoTewLF26lDlz5nD//fczbtw4/vCHP3ghQqX82JEGjmuU3BduX2nb7d1r5O4jirobe78dTG7HctsbKKabHW7689/bLwtHEHx8u23zv9g1pegzo+1dyYknwfn/gJBISOhpfxnMOts2PY1/yF5gLtthB6qL72Vr/S9MtE1F0V1P/P3wgCZ6D7kPU3zeeefxwAMPcMUVVxAZGUlBQQFBQUHU19cTHx/PlVdeSWxsLLNmzTpoX226UaoNOYI8LxsQYGcbM+bAF8PEh20T0AsTbLt9damdKKbxvoCL/gVf/hEufcEmebAjnWaca28wW/AveHqUbTraOt9+SVz+pr2g/PoUu23kbXYgu92rbbNQgMNeSG5hmug95D5M8cSJE7n88ssZPnw4AJGRkbzyyivk5uZy9913ExAQQFBQEP/5z38AmDZtGhMmTKBr1656MVYpX+Ze++85xjbJbPnBXszNGA/9Jx3YPuAX9tFUSJQdimLIVDsf8bw/2/UXPgqJGfZxzWcw9wE7CN1XM2xPo8AwGHhZ65yWdq/0PR3tfJXya2s/sT2ERt5+6IXjvMW2Jp8y1F7YDY0+7sP4V/dKpZRqT/peAFzQ/LZup9tHK/NoKkGllFLtV7tJ9L7WxNRaOsp5KqXaTrtI9KGhoRQVFfl9EjTGUFRURGho6NELK6WUh9pFG31qair5+fkUFhZ6O5RWFxoaSmpqqrfDUEr5kXaR6IOCgkhPT/d2GEop1S61i6YbpZRSx08TvVJK+TlN9Eop5ed87s5YESkEtp7ASyQCe1ooHG/Rc/ANeg6+Qc/BMz2MMUnNbfC5RH+iRCTrcLcBtxd6Dr5Bz8E36DmcOG26UUopP6eJXiml/Jw/JvqZ3g6gBeg5+AY9B9+g53CC/K6NXiml1MH8sUavlFLKjSZ6pZTyc36T6EVkgoisE5FcEbnX2/F4QkS6icg8EVktIjkicptrfbyIfCEiG1x/47wd69GIiENEfhKRj13L6SLyo+vzeFNEgr0d45GISKyIvCMia0VkjYgMb2+fg4jc4fp3tEpEXheR0PbwOYjI8yKyW0RWua1r9r0X6wnX+awQkSHei/yAw5zD313/nlaIyPsiEuu2bbrrHNaJyHmtHZ9fJHoRcQBPAhOB/sAUEenv3ag8Ug/caYzpDwwDbnLFfS/wlTEmA/jKtezrbgPWuC3/P+BRY0xvoAS41itRee5x4DNjTF/gVOy5tJvPQURSgFuBTGPMAMABTKZ9fA4vAhOarDvcez8RyHA9pgH/aaMYj+ZFDj2HL4ABxpiBwHpgOoDr//hk4GTXPk+5clir8YtED5wO5BpjNhljaoE3gElH2cfrjDE7jDFLXc/LscklBRv7S65iLwEXeydCz4hIKnautFmuZQHOBt5xFfHpcxCRGGA08ByAMabWGFNKO/scsKPRholIIBAO7KAdfA7GmO+A4iarD/feTwL+a6xFQKyIdGmbSA+vuXMwxsw1xtS7FhcBjeOPTwLeMMbUGGM2A7nYHNZq/CXRpwB5bsv5rnXthoikAYOBH4FOxpgdrk07gU5eCstTjwH/CzS4lhOAUrd/5L7+eaQDhcALruanWSISQTv6HIwxBcA/gG3YBL8XyKZ9fQ7uDvfet9f/69cAn7qet/k5+Euib9dEJBJ4F7jdGFPmvs3Y/q8+2wdWRC4Edhtjsr0dywkIBIYA/zHGDAb20aSZph18DnHYmmI60BWI4NCmhHbJ19/7oxGR+7DNtK96KwZ/SfQFQDe35VTXOp8nIkHYJP+qMeY91+pdjT9HXX93eys+D4wELhKRLdgms7Ox7d2xriYE8P3PIx/IN8b86Fp+B5v429PncA6w2RhTaIypA97Dfjbt6XNwd7j3vl39XxeRq4ELgSvMgZuW2vwc/CXRLwEyXD0MgrEXOmZ7OaajcrVlPwesMcY84rZpNjDV9Xwq8GFbx+YpY8x0Y0yqMSYN+75/bYy5ApgHXOoq5uvnsBPIE5E+rlXjgNW0o88B22QzTETCXf+uGs+h3XwOTRzuvZ8NXOXqfTMM2OvWxONTRGQCtknzImNMpdum2cBkEQkRkXTsheXFrRqMMcYvHsD52CvbG4H7vB2PhzGfif1JugJY5nqcj23j/grYAHwJxHs7Vg/PZwzwset5T9c/3lzgbSDE2/EdJfZBQJbrs/gAiGtvnwPwELAWWAW8DIS0h88BeB17XaEO++vq2sO994Bge9htBFZiexn56jnkYtviG/9vP+1W/j7XOawDJrZ2fDoEglJK+Tl/abpRSil1GJrolVLKz2miV0opP6eJXiml/JwmeqWU8nOa6JVSys9poldKKT/3/wEok7V0YJmnQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aveDOI5Dfe_a",
        "outputId": "fa436d5e-a28b-415b-a93f-28a3bc64c108"
      },
      "source": [
        "! git commit -a -m \"first commit\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@cbc03bd6b8d7.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeWlGtgCfocW"
      },
      "source": [
        "! git config --global user.email \"farahjabeen024@gmail.com\"\n",
        "! git config --global user.name \"Farah7402\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k--ovYrxgHhT",
        "outputId": "4aaa8a0e-69bf-42c7-da62-2d58a4e1c144"
      },
      "source": [
        "! git config --list"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user.email=farahjabeen024@gmail.com\n",
            "user.name=Farah7402\n",
            "core.repositoryformatversion=0\n",
            "core.filemode=true\n",
            "core.bare=false\n",
            "core.logallrefupdates=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdfzH_FEgVmi",
        "outputId": "a009c993-6b97-4ef5-d980-a87f9bde3ded"
      },
      "source": [
        "! git commit -a -m \"first commit\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "\t\u001b[31m-2DSnake/\u001b[m\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31mBook1/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present\n"
          ]
        }
      ]
    }
  ]
}